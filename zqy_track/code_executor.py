import multiprocessing
import time
import types
import unittest
import traceback
import json
import pandas as pd
from typing import Dict, List, Tuple, Any
import sys
import io
from contextlib import redirect_stdout, redirect_stderr
import tempfile
import os
from table_agents_v2 import Agent

# ç¡®ä¿Windowsä¸Šçš„multiprocessingæ­£å¸¸å·¥ä½œ
if __name__ == '__main__':
    multiprocessing.set_start_method('spawn', force=True)

class CodeExecutorService:
    """ç‹¬ç«‹è¿›ç¨‹ä»£ç æ‰§è¡ŒæœåŠ¡"""
    
    def __init__(self, timeout=30):
        self.timeout = timeout
        self.debug_agent = DebugAgent()
        self.test_agent = TestAgent()
    
    def execute_code_in_process(self, code: str, func_name: str, input_data: Any) -> Dict:
        """åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­æ‰§è¡Œä»£ç """
        # åˆ›å»ºè¿›ç¨‹é—´é€šä¿¡çš„é˜Ÿåˆ—
        result_queue = multiprocessing.Queue()
        
        # åˆ›å»ºå¹¶å¯åŠ¨æ‰§è¡Œè¿›ç¨‹
        process = multiprocessing.Process(
            target=self._execute_code_worker,
            args=(code, func_name, input_data, result_queue)
        )
        
        process.start()
        
        try:
            # ç­‰å¾…ç»“æœï¼Œè®¾ç½®è¶…æ—¶
            result = result_queue.get(timeout=self.timeout)
            process.join(timeout=1)
            
            if process.is_alive():
                process.terminate()
                process.join()
                
            return result
            
        except Exception as e:
            process.terminate()
            process.join()
            return {
                'success': False,
                'error': f'æ‰§è¡Œè¶…æ—¶æˆ–å‡ºé”™: {str(e)}',
                'result': None
            }
    
    def _execute_code_worker(self, code: str, func_name: str, input_data: Any, result_queue: multiprocessing.Queue):
        """å·¥ä½œè¿›ç¨‹ä¸­æ‰§è¡Œä»£ç """
        try:
            # æ•è·è¾“å‡º
            stdout_buffer = io.StringIO()
            stderr_buffer = io.StringIO()
            
            with redirect_stdout(stdout_buffer), redirect_stderr(stderr_buffer):
                # æ‰§è¡Œä»£ç 
                namespace = {}
                exec(code, namespace)
                
                # è·å–å‡½æ•°å¹¶æ‰§è¡Œ
                if func_name not in namespace:
                    raise ValueError(f"å‡½æ•° '{func_name}' æœªåœ¨ä»£ç ä¸­å®šä¹‰")
                
                function = namespace[func_name]
                
                # å¤„ç†è¾“å…¥å‚æ•° - å¦‚æœæ˜¯tupleï¼Œåˆ™è§£åŒ…ä½œä¸ºå¤šä¸ªå‚æ•°
                if isinstance(input_data, tuple):
                    result = function(*input_data)
                else:
                    result = function(input_data)
                
            # è¿”å›ç»“æœ
            result_queue.put({
                'success': True,
                'result': result,
                'stdout': stdout_buffer.getvalue(),
                'stderr': stderr_buffer.getvalue(),
                'error': None
            })
            
        except Exception as e:
            result_queue.put({
                'success': False,
                'result': None,
                'error': str(e),
                'traceback': traceback.format_exc()
            })
    
    def execute_with_debug_and_test(self, code: str, func_name: str, input_data: Any, 
                                   hypothesis: str, max_retries: int = 3) -> Dict:
        """æ‰§è¡Œä»£ç ï¼Œå¦‚æœå‡ºé”™åˆ™ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè°ƒè¯•å’Œæµ‹è¯•"""
        
        original_code = code
        current_code = code
        test_result = {'overall_passed': False}
        for attempt in range(max_retries + 1):
            print(f"\n{'='*50}")
            print(f"ä»£ç æ‰§è¡Œå°è¯• {attempt + 1}/{max_retries + 1}")
            print(f"{'='*50}")
            
            # 1. å°è¯•æ‰§è¡Œä»£ç 
            execution_result = self.execute_code_in_process(current_code, func_name, input_data)
            
            if execution_result['success']:
                print("âœ… ä»£ç æ‰§è¡ŒæˆåŠŸ!")
                
                # 2. ç”Ÿæˆå’Œè¿è¡Œå•å…ƒæµ‹è¯•
                
                test_result = self.test_agent.generate_and_run_tests(
                        current_code, func_name, input_data, execution_result['result'], hypothesis
                )
                
                if test_result['test_execution']['all_passed'] == True:
                    return {
                        'success': True,
                        'result': execution_result['result'],
                        'code': current_code,
                        'execution_details': execution_result,
                        'test_result': test_result,
                        'attempts': attempt + 1
                    }
                
            
            if attempt < max_retries:
                # 4. ä½¿ç”¨è°ƒè¯•ä»£ç†ä¿®å¤ä»£ç 
                if execution_result['success'] == False:
                    print(f"âŒ ä»£ç æ‰§è¡Œå¤±è´¥: {execution_result['error']}")
                    debug_result = self.debug_agent.debug_error_code(
                    current_code, func_name, execution_result['error'], 
                    execution_result.get('traceback', ''), hypothesis
                )
                if test_result['test_execution']['all_passed'] == False:
                    print(f"âŒ å•å…ƒæµ‹è¯•å¤±è´¥: {test_result['test_execution']['test_summary']}")
                    debug_result = self.debug_agent.debug_unittest_code(
                    current_code, func_name, test_result['test_generation']['test_strategy'], 
                    test_result['test_execution']['stdout'], hypothesis)
                

                
                if debug_result['success']:
                    current_code = debug_result['fixed_code']
                    print(f"ğŸ”§ è°ƒè¯•ä»£ç†å·²ä¿®å¤ä»£ç ï¼Œå‡†å¤‡é‡æ–°æ‰§è¡Œ...")
                else:
                    print(f"âŒ è°ƒè¯•ä»£ç†æ— æ³•ä¿®å¤ä»£ç : {debug_result['error']}")
                    break
            else:
                print(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»£ç æ‰§è¡Œå¤±è´¥")
        
        return {
            'success': False,
            'error': execution_result['error'],
            'original_code': original_code,
            'last_attempted_code': current_code,
            'attempts': max_retries + 1
        }
    



class DebugAgent(Agent):
    """ä»£ç è°ƒè¯•ä»£ç†"""
    
    def __init__(self):
        super().__init__()
        self.system_prompt = """
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Pythonä»£ç è°ƒè¯•ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä»£ç æ‰§è¡Œé”™è¯¯ï¼Œå¹¶æä¾›ä¿®å¤åçš„ä»£ç ã€‚
        
        ä½ éœ€è¦ï¼š
        1. åˆ†æé”™è¯¯åŸå› å’Œå †æ ˆè·Ÿè¸ª
        2. ç†è§£ä»£ç çš„é¢„æœŸåŠŸèƒ½
        3. æä¾›ä¿®å¤åçš„å®Œæ•´ä»£ç 
        4. ç¡®ä¿ä¿®å¤åçš„ä»£ç ç¬¦åˆåŸå§‹hypothesisçš„è¦æ±‚
        """
    
    def debug_error_code(self, code: str, func_name: str, error: str, 
                          traceback_info: str, hypothesis: str) -> Dict:
        """è°ƒè¯•å¹¶ä¿®å¤ä»£ç """
        
        user_prompt = f"""
        ä»¥ä¸‹Pythonä»£ç åœ¨æ‰§è¡Œæ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·åˆ†æé”™è¯¯åŸå› å¹¶æä¾›ä¿®å¤åçš„ä»£ç ã€‚

        <original_code>
        {code}
        </original_code>

        <function_name>
        {func_name}
        </function_name>

        <error_message>
        {error}
        </error_message>

        <traceback>
        {traceback_info}
        </traceback>


        <hypothesis>
        {hypothesis}
        </hypothesis>

        è¯·åˆ†æé”™è¯¯åŸå› å¹¶æä¾›ä¿®å¤åçš„ä»£ç ã€‚ä¿®å¤åçš„ä»£ç å¿…é¡»ï¼š
        1. ä¿æŒåŸå§‹å‡½æ•°åä¸å˜
        2. ä¿æŒå‡½æ•°çš„è¾“å…¥è¾“å‡ºæ¥å£ä¸å˜
        3. ç¬¦åˆhypothesisä¸­æè¿°çš„åŠŸèƒ½è¦æ±‚
        4. ä¿®å¤æ‰€æœ‰è¯­æ³•å’Œé€»è¾‘é”™è¯¯
        5. ç¡®ä¿è¿”å›æ ¼å¼ä¸º[(elem_name, row, col), ...]çš„åˆ—è¡¨

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š

        <analysis>
        åˆ†æé”™è¯¯åŸå› å’Œä¿®å¤æ€è·¯
        </analysis>

        <fixed_code>
        ä¿®å¤åçš„å®Œæ•´ä»£ç 
        </fixed_code>
        """
        
        prompt_msgs = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            raw_response = self.get_LLM_response(prompt_msgs)
            
            analysis = self.extract_content("analysis", raw_response)
            fixed_code = self.extract_content("fixed_code", raw_response)
            
            if not fixed_code:
                return {
                    'success': False,
                    'error': 'æ— æ³•ä»å“åº”ä¸­æå–ä¿®å¤åçš„ä»£ç ',
                    'raw_response': raw_response
                }
            
            return {
                'success': True,
                'analysis': analysis,
                'fixed_code': fixed_code,
                'raw_response': raw_response
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è°ƒè¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}',
                'traceback': traceback.format_exc()
            }

    def debug_unittest_code(self, code: str, func_name: str, test_strategy: str, 
                          stdout: str, hypothesis: str) -> Dict:
        """è°ƒè¯•å¹¶ä¿®å¤ä»£ç """
        
        user_prompt = f"""
        ä»¥ä¸‹Pythonä»£ç åœ¨æ‰§è¡Œæ—¶å‡ºç°äº†é”™è¯¯ï¼Œè¯·åˆ†æé”™è¯¯åŸå› å¹¶æä¾›ä¿®å¤åçš„ä»£ç ã€‚

        <original_code>
        {code}
        </original_code>

        <function_name>
        {func_name}
        </function_name>

        <test_strategy>
        {test_strategy}
        </test_strategy>

        <stdout>
        {stdout}
        </stdout>


        <hypothesis>
        {hypothesis}
        </hypothesis>

        è¯·åˆ†æé”™è¯¯åŸå› å¹¶æä¾›ä¿®å¤åçš„ä»£ç ã€‚ä¿®å¤åçš„ä»£ç å¿…é¡»ï¼š
        1. ä¿æŒåŸå§‹å‡½æ•°åä¸å˜
        2. ä¿æŒå‡½æ•°çš„è¾“å…¥è¾“å‡ºæ¥å£ä¸å˜
        3. ç¬¦åˆhypothesisä¸­æè¿°çš„åŠŸèƒ½è¦æ±‚
        4. ä¿®å¤å•å…ƒæµ‹è¯•å¤±è´¥çš„åŸå› 
        5. ç¡®ä¿è¿”å›æ ¼å¼ä¸º[(elem_name, row, col), ...]çš„åˆ—è¡¨

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š

        <analysis>
        åˆ†æé”™è¯¯åŸå› å’Œä¿®å¤æ€è·¯
        </analysis>

        <fixed_code>
        ä¿®å¤åçš„å®Œæ•´ä»£ç 
        </fixed_code>
        """
        
        prompt_msgs = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            raw_response = self.get_LLM_response(prompt_msgs)
            
            analysis = self.extract_content("analysis", raw_response)
            fixed_code = self.extract_content("fixed_code", raw_response)
            
            if not fixed_code:
                return {
                    'success': False,
                    'error': 'æ— æ³•ä»å“åº”ä¸­æå–ä¿®å¤åçš„ä»£ç ',
                    'raw_response': raw_response
                }
            
            return {
                'success': True,
                'analysis': analysis,
                'fixed_code': fixed_code,
                'raw_response': raw_response
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è°ƒè¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}',
                'traceback': traceback.format_exc()
            }





class TestAgent(Agent):
    """æµ‹è¯•ä»£ç†"""
    
    def __init__(self):
        super().__init__()
        self.system_prompt = """
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„Pythonå•å…ƒæµ‹è¯•ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç»™å®šçš„ä»£ç ç”Ÿæˆå…¨é¢çš„å•å…ƒæµ‹è¯•ï¼Œ
        éªŒè¯ä»£ç æ˜¯å¦æ­£ç¡®å®ç°äº†é¢„æœŸåŠŸèƒ½ã€‚
        """
    
    def generate_and_run_tests(self, code: str, func_name: str, input_data: Any, 
                              execution_result: Any, hypothesis: str) -> Dict:
        """ç”Ÿæˆå¹¶è¿è¡Œå•å…ƒæµ‹è¯•"""
        
        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        test_generation_result = self.generate_test_cases(
            code, func_name, input_data, execution_result, hypothesis
        )
        
        if not test_generation_result['success']:
            return test_generation_result
        
        # è¿è¡Œæµ‹è¯•ç”¨ä¾‹
        test_execution_result = self.run_test_cases(
            code, test_generation_result['test_code']
        )
        
        return {
            'success': True,
            'test_generation': test_generation_result,
            'test_execution': test_execution_result,
            'overall_passed': test_execution_result['success'] and test_execution_result['all_passed']
        }
    
    def generate_test_cases(self, code: str, func_name: str, input_data: Any, 
                           execution_result: Any, hypothesis: str) -> Dict:
        """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        
        user_prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ä»£ç ç”Ÿæˆå…¨é¢çš„å•å…ƒæµ‹è¯•ç”¨ä¾‹ã€‚

        <code_to_test>
        {code}
        </code_to_test>

        <function_name>
        {func_name}
        </function_name>

        <sample_input>
        {str(input_data)[:1000]}...
        </sample_input>

        <sample_output>
        {str(execution_result)[:1000]}...
        </sample_output>

        <hypothesis>
        {hypothesis}
        </hypothesis>

        è¯·ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ¥éªŒè¯ï¼š
        1. å‡½æ•°çš„åŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£ç¡®
        2. è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆè¦æ±‚[(elem_name, row, col), ...]
        3. æ‰€æœ‰rowå’Œcoléƒ½æ˜¯æ­£æ•´æ•°
        4. æ²¡æœ‰ä½ç½®é‡å 
        5. ç»“æœæ˜¯å¦ç¬¦åˆhypothesisä¸­æè¿°çš„è§„å¾‹

        è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š

        <test_strategy>
        æµ‹è¯•ç­–ç•¥å’Œæµ‹è¯•ç”¨ä¾‹è®¾è®¡æ€è·¯
        </test_strategy>

        <test_code>
        import unittest
        import pandas as pd
        
        # åœ¨æ­¤å¤„åŒ…å«è¢«æµ‹è¯•çš„ä»£ç 
        {code}
        
        class TestGeneratedFunction(unittest.TestCase):
            # ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
            pass
        if __name__ == "__main__":
            # ä½¿ç”¨TestRunneræ¥æ§åˆ¶è¾“å‡ºæµ
            loader = unittest.TestLoader()
            suite = loader.loadTestsFromTestCase(DemoTest)
            runner = unittest.TextTestRunner(stream=sys.stdout, verbosity=2)
            result = runner.run(suite)
            </test_code>
        """
        
        prompt_msgs = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            raw_response = self.get_LLM_response(prompt_msgs)
            
            test_strategy = self.extract_content("test_strategy", raw_response)
            test_code = self.extract_content("test_code", raw_response)
            
            if not test_code:
                return {
                    'success': False,
                    'error': 'æ— æ³•ä»å“åº”ä¸­æå–æµ‹è¯•ä»£ç ',
                    'raw_response': raw_response
                }
            
            return {
                'success': True,
                'test_strategy': test_strategy,
                'test_code': test_code,
                'raw_response': raw_response
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {str(e)}',
                'traceback': traceback.format_exc()
            }
    
    def run_test_cases(self, original_code: str, test_code: str) -> Dict:
        """è¿è¡Œæµ‹è¯•ç”¨ä¾‹"""
        
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥è¿è¡Œæµ‹è¯•
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(test_code)
                test_file = f.name
            
            # æ•è·æµ‹è¯•è¾“å‡º
            stdout_buffer = io.StringIO()
            stderr_buffer = io.StringIO()
            
            with redirect_stdout(stdout_buffer), redirect_stderr(stderr_buffer):
                # åœ¨ç‹¬ç«‹çš„å‘½åç©ºé—´ä¸­è¿è¡Œæµ‹è¯•
                namespace = {"__name__": "__main__"}
                exec(test_code, namespace)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(test_file)
            
            stdout_content = stdout_buffer.getvalue()
            stderr_content = stderr_buffer.getvalue()
            
            # ç®€å•åˆ†ææµ‹è¯•ç»“æœ
            if 'FAILED' in stdout_content or 'ERROR' in stdout_content:
                all_passed = False
                test_summary = "éƒ¨åˆ†æµ‹è¯•å¤±è´¥"
            elif 'OK' in stdout_content:
                all_passed = True
                test_summary = "æ‰€æœ‰æµ‹è¯•é€šè¿‡"
            else:
                all_passed = False
                test_summary = "æµ‹è¯•ç»“æœä¸æ˜ç¡®"
            
            return {
                'success': True,
                'all_passed': all_passed,
                'test_summary': test_summary,
                'stdout': stdout_content,
                'stderr': stderr_content
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'è¿è¡Œæµ‹è¯•æ—¶å‡ºé”™: {str(e)}',
                'traceback': traceback.format_exc()
            }


def enhanced_code_execution(code: str, func_name: str, input_data: Any, 
                          hypothesis: str, max_retries: int = 3) -> Dict:
    """å¢å¼ºçš„ä»£ç æ‰§è¡Œå‡½æ•°ï¼ŒåŒ…å«è°ƒè¯•å’Œæµ‹è¯•åŠŸèƒ½"""
    
    executor = CodeExecutorService()
    return executor.execute_with_debug_and_test(
        code, func_name, input_data, hypothesis, max_retries
    )


if __name__ == '__main__':
    # æµ‹è¯•ç¤ºä¾‹
    test_code = """
import pandas as pd

def test_function(df):
    results = []
    for i, (elem, row) in enumerate(df.iterrows()):
        results.append((elem, i+1, 1))
    return results
"""
    
    test_input = pd.DataFrame({
        'A': [1, 2, 3],
        'B': [4, 5, 6]
    })
    
    test_hypothesis = "æ ¹æ®å…ƒç´ å±æ€§å°†å…ƒç´ æ’åˆ—åœ¨å‘¨æœŸè¡¨æ ¼ä¸­"
    
    result = enhanced_code_execution(test_code, 'test_function', test_input, test_hypothesis)
    print(json.dumps(result, indent=2, ensure_ascii=False)) 